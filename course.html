<!DOCTYPE html>
<!-- KaTeX requires the use of the HTML5 doctype. Without it, KaTeX may not render properly -->
<html>
  <head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
  
<title>The Maximum Likelihood Degree
</title>
<meta name="viewport" content="width=device-width, user-scalable=no" />
<link rel="preload" href="fonts/open-sans-v17-latin-regular.woff2" as="font">
<link rel="shortcut icon" type="image/png" href="favicon.png"/>
<style>

/* website design lifted from https://jeffhuang.com/designed_to_last */

:root {
	--accent-color: #C988C3;
	--back-color: #13A1A3;
	--link-color: #55ABAD;
}

/* open-sans-regular - latin */
@font-face {
  font-family: 'Open Sans';
  font-style: normal;
  font-weight: 400;
  src: local('Open Sans Regular'), local('OpenSans-Regular'),
       url('fonts/open-sans-v17-latin-regular.woff2') format('woff2'); /* Chrome 26+, Opera 23+, Firefox 39+ */
}
/* open-sans-700 - latin */
@font-face {
  font-family: 'Open Sans';
  font-style: normal;
  font-weight: 700;
  src: local('Open Sans Bold'), local('OpenSans-Bold'),
       url('fonts/open-sans-v17-latin-700.woff2') format('woff2'); /* Chrome 26+, Opera 23+, Firefox 39+ */
}

/* minimalist reset */
* {
	padding: 0;
	margin: 0;
	font-size: 1em;
}

body {
	background-color: var(--back-color);
	font-family: 'Open Sans',sans-serif;
}

main {
	margin: 0 auto;
	padding: 30px 140px 0 140px;
	max-width: 650px;
	min-height: 100vh;
	background-color: white;
}

h1 {
	font-size: 1.5em;
	font-weight: 700;
	display: inline;
	margin-right: 5px;
}

.accent {
	color: var(--accent-color);
}

h2 {
	margin-top: 50px;
	font-size: 1.2em;
}

h3 {
    margin-top: 10px;
	font-weight: 400;
	/*margin-bottom: 30px;*/
}

h4 {
	margin-top: 0px;
	font-weight: 400;
	font-style: italic;
	color: gray;
	/*text-align:right;*/
}

footer {
	text-align: right;
	margin-top: 80px;
	padding-bottom: 20px;
}

p {
	line-height: 1.5em;
	margin-top: 20px;
	display: block;
}

a {
	color: darkgray;
	text-decoration: none;
	color: var(--link-color);
}

ol {
    counter-reset: item; 
}
ol>li {
    counter-increment: item; 
    list-style: none inside; 
    margin: 20px 0;
    overflow: hidden;
    line-height: 1.5em;
}
ol>li:before {
    content: counter(item) ;
    margin-right: 10px;
    padding: 0px;
    border-radius: 50%;
    width: 25px;
    background: var(--accent-color);
    color: white;
    text-align: center; 
    float: left;
}

kbd {
	font-family: monospace;
	font-size: 12pt;
}

img {
	max-width: 100%;
	min-width: 100px;
	height: auto;
}

@media (max-width: 650px) {
  main {
  	max-width: 650px;
    padding: 20px;
  }
  h2 {
    font-size: 1.2em;
  }
  :root {
  	--back-color: white;
  }
}

</style>
  </head>
<body>

<main>
<center>
<h1>The Maximum Likelihood Degree</h1>

<h3>A graduate course at KTH Stockholm</h3>
</center>

<h2></h2>
<p>
If you're interested in attending this course, please fill out this short form to get email updates: <a href=https://docs.google.com/forms/d/e/1FAIpQLScB_pUtGhx_ZJXc6MFklknJ62T61BK1zLWnHrQWaQ4hsFR3FQ/viewform?usp=sf_link>link</a>
</p>

<h2>Description</h2>
<p>
This is a graduate course in algebraic statistics focusing on the maximum likelihood degree (MLD). The MLD is an invariant of algebraic statistical models that measures the algebraic complexity of the maximum likelihood estimation problem on that model. Calculating this number for various families of discrete or continuous models is interesting because it allows exhaustive solutions to this estimation problem.
</p>
<p>
After reviewing the basics and defining the MLD for discrete and Gaussian algebraic models, the course features practical computing sessions to get practice in handling this invariant and computing with it. The last part of the course is theoretical and aimed at understanding recent research on discrete statistical models with maximum likelihood degree one. 
</p>
<h2>Outline</h2>
<ol><li>
Nov 2: Introduction – Discrete and Gaussian statistical models, maximum likelihood estimation, algebraic geometry basics. <i>No assignments.</i> [<a href=ml-degree-course.pdf>notes</a>]
</li>
<li>
Nov 9: Algebraic statistical models and their MLD. <br /><b>Literature:</b> Sullivant, Algebraic Statistics, Section 7.1 without the examples.
<br /><b>Exercise:</b> State and prove a version of Theorem 7.1.2 for algebraic Gaussian models.
</li>
<li>
Nov 16: Practical session – Computing the MLD. [<a href=course2.m2>code</a>]
<br /><b>Literature:</b> The examples in Sullivant, Section 7.1.
<br /><b>Exercise:</b> Sullivant, Section 7.5, Exercise 7.2.
</li>
<li>
Nov 23: Practical session – Using the MLD for likelihood estimation. [<a href=course-gaussian.jl>code</a>]
<br /><b>Literature:</b> Sturmfels, Timme, and Zwiernik, Estimating linear covariance models with numerical nonlinear algebra, Section 5.
[<a href=https://arxiv.org/abs/1909.00566>link</a>]
<br /><b>Exercise:</b> Verify Example 3.5 in the paper using the Julia package LinearCovarianceModels.jl.
</li>
<li>
Nov 30: Discrete MLD one – Problem setup.
<br /><b>Literature:</b> Huh, Varieties with maximum likelihood degree one, Sections 1.1, 1.2, 3.1, 3.2.
[<a href=https://arxiv.org/abs/1301.2732>link</a>]
<br /><b>Exercise:</b> When does a subvariety of
<span class="math inline">\((\mathbb C^*)^2\)</span> given as the restriction of a line in
<span class="math inline">\(\mathbb C^2\)</span>
have ML degree one?
</li>
<li>
Dec 7: Discrete MLD one – Horn uniformizations. <br /><b>Literature:</b> Huh, Sections 3.3, 3.4, 3.5.
<br /><b>Exercise:</b> Adapt the first part of Example 7 to the case of three binary random variables. Give the corresponding scaling vector
<span class="math inline">\(\mathbf d\)</span> and Horn matrix <span class="math inline">\(B\)</span>.
</li>
<li>
Dec 14: Discrete MLD one – Discriminantal varieties. <br /><b>Literature:</b> Huh, Sections 1.3, 3.6, 3.7.
<br /><b>Exercise:</b> Adapt the second part of Example 7 to the case of three binary random variables. Describe the corresponding <span class="math inline">\(A\)</span>-discriminant <span class="math inline">\(\Delta_A\)</span> and monomial map <span class="math inline">\(\mathbf d * \phi^B\)</span>.
</li>
</ol>
<h2>Course Data</h2>
<p>
<b>Code:</b> FSF3961 (Selected Topics in Mathematical Statistics)
<br />
<b>ECTS:</b> 7,5
<br />
<b>Teacher:</b> Orlando Marigliano (orlandom at kth.se)
<br />
<b>Examiner:</b> Henrik Hult
<br />
<b>Place:</b> Room 3721, Lindstedtsvägen 25 [<a href = https://www.kth.se/places/room/id/c576a540-76d6-4a29-814b-22d976a8f41f>link</a>]
<br />
<b>Timespan:</b> Fall term 2021-2022, Reading period 2, every Tuesday 14:15-16:00
<br />
<b>Prerequisites:</b> Intermediate algebra, basic probability theory knowledge
</p>

<h2>
Participation and Examination
</h2>
<p>
Participants are expected to have read the literature assigned to each session ahead of time. Additionally, Please prepare for the practical sessions by installing
<a href=http://www2.macaulay2.com/Macaulay2/Downloads/>
Macaulay2</a>,
<a href=https://julialang.org/downloads/>
Julia</a>,
and
<a href=https://juliahub.com/ui/Packages/LinearCovarianceModels/GW5fU/0.2.1>
LinearCovarianceModels.jl
</a>
on your computer and running a basic 1+1=2 computation in both systems ahead of time.
</p><p>
Participants who wish to pass the course should submit written solutions to the homework exercises and present one of their solutions to the group. A solution to an exercise assigned to a session should be handed in before the following session. It can be presented either during its session or in the following session, if there is one. 
</p><p>
In case more than six participants wish to pass the course, those remaining can do so by doing an additional short presentation at the end of the course.
</p>

<footer>Course URL: <a href = https://orlandomarigliano.com/course>https://www.orlandomarigliano.com/course</a></footer>
</main>

</body>
</html>
